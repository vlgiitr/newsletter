# Newsletter

This repository serves as a weekly list of interesting reads related to deep learning found by our group members. If you found anything interesting throughout the week, feel free to open an issue or pull request!

## 7: January 19, 2020

1. Interpreting Deep Learning Models for Computer Vision.[[Link]](https://medium.com/google-developer-experts/interpreting-deep-learning-models-for-computer-vision-f95683e23c1d)
2. Trends in NLP.[[Link]](https://podcasts.google.com/?feed=aHR0cDovL3R3aW1sYWkubGlic3luLmNvbS9yc3M&episode=YmEzMDFhNWQtN2QxYi00MDgyLTkzNjktNWVkNzEyYjk2MjE5)
3. Deepmind: Relation between neuroscience & AI.[[Link]](https://deepmind.com/blog/article/Dopamine-and-temporal-difference-learning-A-fruitful-relationship-between-neuroscience-and-AI)
4. Everybody’s Talkin’: Let Me Talk as You Want.[[Link]](https://www.youtube.com/watch?v=tNPuAnvijQk&feature=youtu.be&fbclid=IwAR1QE5CAtmviQ-3LdV9dd3qSn1Offde5Mg1f4eFY5B0lXJMlBU6BQ0fYvP0)
5. Why should you open-source models along with your paper?[[Link]](https://twitter.com/Thom_Wolf/status/1216990543533821952?s=19)
6. Solving advanced mathematical problems with neural networks.[[Link]](https://twitter.com/facebookai/status/1217148075862417408?s=19)
7. List of global AI/ML conferences in 2020[[Link]](https://www.facebook.com/groups/DeepNetGroup/permalink/1064782990581249/)


## 6: January 12, 2020

1. SIGGRAPH 2018.[[Link]](https://www.youtube.com/watch?v=vppFvq2quQ0)
2. Tutorials for OpenCV, computer vision, deep learning, image processing, neural networks and artificial intelligence.[[Link]](http://www.aishack.in/)
3. GlyphNet[[Link]](https://github.com/noahtren/GlyphNet)
4. Papers Explained-Henry AI Labs series[[Link]](https://m.youtube.com/chann…/UCHB9VepY6kYvZjj0Bgxnpbw/videos)
5. Autograd & Computation Graphs.[[Link]](https://blog.paperspace.com/pytorch-101-understanding-grap…/)
6. Machine learning interviews: Lessons from both sides.[[Link]](https://twitter.com/chipro/status/1196232680364376064?s=19)


## 5: January 5, 2020

1. Four Lessons I learnt after my first full-time job after college [[Link]](https://huyenchip.com/2019/12/23/leaving-nvidia-lessons.html)
2. Becoming an independent researcher and getting published in ICLR with the spotlight [[Link]](https://link.medium.com/2f7QuM5OP2)
3. A recipe for training neural networks [[Link]](https://karpathy.github.io/2019/04/25/recipe/)
4. Instance noise- A trick for stabilising GAN training [[Link]](https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/)
5. Career advice for recent Computer Science graduates [[Link]](https://huyenchip.com/2018/10/08/career-advice-recent-cs-graduates.html)
6. A summary of advancement in AI in this decade [[Link]](https://l.facebook.com/l.php?u=https%3A%2F%2Fm.youtube.com%2Fwatch%3Fv%3D6SWpN64Ivb4%26amp%253Bfeature%3Dyoutu.be%26fbclid%3DIwAR22O_Gp7vWtTjlBIKAWoX3L_7KkBM5R8G5riUqrO__1_YBXX5pLBIoLEEU&h=AT1wTl4sAKJez_Pcpyrck8-Ti8Fmt4s-chGjxqBxmX2KgcMQHF2tlnydBpFB_PE75_nKhnxQvAGeowSbp3jNLYCkbR5oYKWerjx4QnaEDp11B4QPHeyIzSpyXJtdESTJbi7kCdTUVy7XtQlEhrMe-64Fv5BhpdKLd-cSpWP4x6h5-Y5PBvH9juL89vaq0b41gbfY_-ueWLrUlOeAIR-WYALM2JMRKoKD8LIUsd0v91ZWpXBYpgXGYfvmWDvFOMeQ8ARduiifE-C04mYJ0xC0nW3OyPF92W-vjOLpsz5tmW4kdNblxh_SYJBrftcqv1B9sc7BqaM0dZUsCQRsKisrXzqvesprOyNOL6EO6Fj2hJzGLOVRKn_5pojGgce1N9NTyqXXApoIEm3dHkte9p7q_DzhTOzPzCNCb7qeV_uQqFONoSnYCpHyYE6Y3TCddqITzAlvRkxN_sfv2C7km0y4myIcqCkFyP3js9dTnBks0sWBh02BjPd2TIDqFGRpFez7dQhMd9v_qUbspJ7HHvVYYbMjR_mYNCYYs6IaLhziIQrCo8AGShQNngulAR6cIn2u_EbL7vW7EbPJlFmSplU_bWTtU65kvdDN00cOi-YDkQvHbH3_2fwYexTTr3IeHU2Cz5TsciATXU8)
7. A conceptual explanation of Bayesian Hyperparameter Optimisation for Machine Learning [[Link]](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f)
8. Reinforcement Learning series: [[Link]](https://www.youtube.com/watch?v=SinprXg2hUA&list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A&index=1)

## 4: December 29, 2019

1. Blog on the ACM 2017 paper- Get to the point [[Link]](http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html)
2. Text Summarisation in Machine Learning [[Link]](https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/)
3. 7 loss functions in Machine Learning Algorithms [[Link]](https://medium.com/analytics-vidhya/a-detailed-guide-to-7-loss-functions-for-machine-learning-algorithms-26e11b6e700b)
4. How to read a paper [[Link]](http://ccr.sigcomm.org/online/files/p83-keshavA.pdf)
5. Pytorch tutorials [[Link]](https://github.com/Tessellate-Imaging/Pytorch_Tutorial)
6. Four lessons I learnt after my first full time job after college [[Link]](https://huyenchip.com/2019/12/23/leaving-nvidia-lessons.html)

## 3: December 22, 2019

1. ICCV Best Paper Honorable Mention Presentation [[Link]](https://www.youtube.com/watch?v=V2v0qEPsjr0)
2. Representation Learning with Contrastive Predictive Coding [[Link]](https://arxiv.org/abs/1807.03748)
3. Google AI Blog on Pixel 4 Portrait Mode Improvements [[Link]](https://ai.googleblog.com/2019/12/improvements-to-portrait-mode-on-google.html?m=1)
4. Step-by-Step Explanation of LSTM and GRU Working [[Link]](https://youtu.be/8HyCNIVRbSU)
5. Georgia Tech Machine Learning Theory Course Website [[Link]](https://cs7545.wordpress.com/)
6. Pytorch Named Tensor Tutorial [[Link]](https://pytorch.org/tutorials/intermediate/named_tensor_tutorial.html)
7. What does the Python Ellipsis object do?  [[Link]](https://stackoverflow.com/a/773472)
8. New DL Algorithms beyond Backpropagation (IBM Developers UnConference 2018) [[Link]](https://www.researchgate.net/publication/322617800_New_Deep_Learning_Algorithms_beyond_Backpropagation_IBM_Developers_UnConference_2018_Zurich)

## 2: December 15, 2019

1. NeurIPS Paper Awards 2019 [[Link]](https://medium.com/@N…/neurips-2019-paper-awards-807e41d0c1e)
2. Reinforcement Learning Upside Down [[Link]](https://arxiv.org/pdf/1912.02875.pdf)
3. Probabilistic Graphical Models [[Link]](http://www.cs.cmu.edu/~epxing/Class/10708-19/)
4. Deep Learning on Graphs with Graphical Convolutional Networks [[Link]](https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780)
5. Spiking Neural Networks [[Link]](https://towardsdatascience.com/spiking-neural-networks-the-next-generation-of-machine-learning-84e167f4eb2b)
6. Machine Learning Glossary [[Link]](https://yanndubs.github.io#model_evaluation/accuracy_score before feature selection
generate_accuracy_and_heatmap(lr_model, X_test, y_test)
#model_evaluation/accuracy_score before feature selection
generate_accuracy_and_heatmap(lr_model, X_test, y_test)
#model_evaluation/accuracy_score before feature selection
generate_accuracy_and_heatmap(lr_model, X_test, y_test)
/machine-learning-glossary/)

## 1: December 08, 2019

1. LSTM vs Transformer: An Honest paper by Smerity [[Link]](https://arxiv.org/pdf/1911.11423.pdf)
2. Stanford CS-221, CS-229, CS-230 Cheat Sheets [[Link]](https://stanford.edu/~shervine/teaching/)
3. True Artificial Intelligence Will Change Everything | Juergen Schmidhuber [[Link]](https://youtu.be/-Y7PLaxXUrs)
4. Self-Training with Noisy Student Improves ImageNet Classification [[Link]](https://arxiv.org/abs/1911.04252)
5. Self-supervised Representation Learning Blog by Lilian Weng [[Link]](https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html)
